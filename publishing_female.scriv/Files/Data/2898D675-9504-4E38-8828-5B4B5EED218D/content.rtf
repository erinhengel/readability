{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf400
{\fonttbl\f0\fnil\fcharset204 PTSerif-Regular;\f1\fswiss\fcharset0 Helvetica;\f2\fnil\fcharset204 PTMono-Regular;
}
{\colortbl;\red255\green255\blue255;\red0\green0\blue128;\red0\green128\blue64;}
{\*\expandedcolortbl;;\csgenericrgb\c0\c0\c50196;\csgenericrgb\c0\c50196\c25098;}
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\sl288\slmult1\sa200\pardirnatural\partightenfactor0

\f0\fs28 \cf0 A gender readability gap exists. It's still there after including editor, journal and year effects---meaning we cannot blame specific policies or attitudes in the 50s, long since overcome. The gap is unaffected by field controls, so it's not that women research topics that are easier to explain. Perhaps it's caused by factors correlated with gender but actually linked to authors' (or co-authors') competence as economists or fluency in English? If so, institution and native speaker dummies would reduce it. They do {\field{\*\fldinst{HYPERLINK "scrivcmt://A24BA9ED-A542-4848-AD36-9DAB7C943837"}}{\fldrslt not.}}\
The gap grows between first draft and final publication and over the course of women's careers. This precludes systemic bias by article- or author-specific fixed effects---*
\i e.g.
\i0 *, inborn advantages and one-off improvements in response to external circumstances unrelated to peer review.\
It likewise rules out gender differences in (i) biology/behaviour---*
\i e.g.
\i0 *, sensitivity to referee {\field{\*\fldinst{HYPERLINK "scrivcmt://622C5547-5E2B-44C9-A3AD-02041C888EED"}}{\fldrslt criticism}}---or (ii) knowledge about referee expectations. If diligently addressing every referee concern has no apparent upside---acceptance rates are unaffected---and a very clear downside---constant redrafting takes time---shouldn't even oversensitive, ill-informed women *
\i eventually
\i0 * re-examine beliefs... and start acting more like 
\f1\fs24 \cf2 <$Scr_Cs::1>
\f2\fs28 [men](#Theorem1)
\f1\fs24 \cf0 <!$Scr_Cs::1>
\f0\fs28 ? Yet this is not what we observe. The largest investments in writing well are made by female economists with greatest exposure to peer review---*
\i i.e.
\i0 *, those with the best opportunity to update their priors.\
Women's papers are more likely assigned female referees{\field{\*\fldinst{HYPERLINK "scrivcmt://4F6E750D-A392-4C06-B9A7-134B13CEE6CB"}}{\fldrslt 
\f1\fs24 \cf3 <$Scr_Cs::2>
\f2\fs28 [#Abrevaya2012,Gilbert1994]
\f1\fs24 \cf0 <!$Scr_Cs::2>
\f0\fs28 .}} If female referees are more demanding critics, clearer writing could reflect their tougher {\field{\*\fldinst{HYPERLINK "scrivcmt://F0C88D68-BD9A-409A-8856-7FBA6E6C78DB"}}{\fldrslt reviews.}} Women concentrate in particular fields, so it's natural their papers are more often assigned female referees. However, for the readability gap to exist only because of specialisation, controlling for *
\i JEL
\i0 * classification should explain {\field{\*\fldinst{HYPERLINK "scrivcmt://5A28673C-3820-4B3B-868E-CB4A4EDD212D"}}{\fldrslt it.}} It does not. In fact, even including 718 tertiary *
\i JEL
\i0 * category dummies has virtually no effect. So if referee assignment is causing the gap, it's only because journals disproportionately refer female-authored papers to the toughest critics. Meaning it isn't referees who are biased---it's {\field{\*\fldinst{HYPERLINK "scrivcmt://32BF0BA1-CFA6-4473-BF9B-76DE6D7EEABC"}}{\fldrslt editors.}}\
A final alternative is rather uncomfortable. Perhaps female-authored manuscripts deserve more criticism because they aren't as good? As mentioned earlier, factors correlated with gender but actually related to competency should decline when appropriate proxies are included. The sample itself is one such proxy---these are, after all, only articles published in the top four economics journals. Adding other controls---author institution, total article count, citation counts and published order in an issue---has no {\field{\*\fldinst{HYPERLINK "scrivcmt://F925F83E-314F-4BC6-B733-BC7A25C3308D"}}{\fldrslt effect.}} The gap is widest for the most productive economists and even exists among articles originally released as NBER working papers---both presumably very clear signals of merit.\
Yet I cannot rule out the possibility that women's work is systematically worse than men's---or that the female and male authors in 
\f1\fs24 \cf2 <$Scr_Cs::1>
\f2\fs28 [][SEUMatching]
\f1\fs24 \cf0 <!$Scr_Cs::1>
\f0\fs28  are not really equivalent. (To decide for yourself, see 
\f1\fs24 \cf2 <$Scr_Cs::1>
\f2\fs28 [][AppendixMatchingNames]
\f1\fs24 \cf0 <!$Scr_Cs::1>
\f0\fs28 .) And if this is true, referees *
\i should
\i0 * peruse our papers more carefully---a byproduct of which could be better written papers after-the-fact or more attractive prose compensating for structural weaknesses before {\field{\*\fldinst{HYPERLINK "scrivcmt://C3DB6C1C-4BFD-44BF-ABC2-4D7837413DC6"}}{\fldrslt it.}}\
"Quality" is subjective; measurement, not easy. Nevertheless, attempts using citation counts and journal acceptance rates do not indicate that men's research is any better: as discussed in 
\f1\fs24 \cf2 <$Scr_Cs::1>
\f2\fs28 [][SEUModel]
\f1\fs24 \cf0 <!$Scr_Cs::1>
\f0\fs28 , gender has virtually zero impact on the {\field{\*\fldinst{HYPERLINK "scrivcmt://B97ACE7B-9FA1-406B-8C21-9131BF4DA916"}}{\fldrslt latter;}} a review of past studies on male vs. female citations find four in which women's papers received fewer, six where they were cited more and eight with no significant difference
\f1\fs24 \cf3 <$Scr_Cs::2>
\f2\fs28 [#Ceci2014]
\f1\fs24 \cf0 <!$Scr_Cs::2>
\f0\fs28 .\
More complicated, multi-factor explanations could resolve inconsistencies present when each is analysed in isolation. Perhaps female economists are perfectionists, and it gets stronger with {\field{\*\fldinst{HYPERLINK "scrivcmt://6268F7E6-D943-4F50-8BA5-99582C1BC08F"}}{\fldrslt age?}} Maybe women actually enjoy being poorly informed, overconfident and sensitive to criticism---or (more likely) I may have otherwise misspecified the author's objective function in 
\f1\fs24 \cf2 <$Scr_Cs::1>
\f2\fs28 [][SEUModel]
\f1\fs24 \cf0 <!$Scr_Cs::1>
\f0\fs28 . It is also possible that the statistically significant relationships this paper documents are unfortunate (particularly for me!) flukes.\
Still, no explanation matches the simplicity and believability of biased referees and/or editors. Coherence and economy do not establish fact, but they are useful guides. This single explanation neatly accounts for all observed patterns. If reviewers apply higher standards to female-authored papers, those papers undergo more thorough review. Added scrutiny should improve women's exposition but lengthen review times---as seen in 
\f1\fs24 \cf2 <$Scr_Cs::1>
\f2\fs28 [][Duration]
\f1\fs24 \cf0 <!$Scr_Cs::1>
\f0\fs28 . The rewards from clearer writing are presumably internalised, meaning women gradually improve---which they do, as illustrated in 
\f1\fs24 \cf2 <$Scr_Cs::1>
\f2\fs28 [][Experience]
\f1\fs24 \cf0 <!$Scr_Cs::1>
\f0\fs28 .\
Moreover, several studies document a gender difference in critical feedback of similar form---employee performance reviews and student {\field{\*\fldinst{HYPERLINK "scrivcmt://950C333A-B261-4D03-865B-AF340CFA5B77"}}{\fldrslt evaluations.}} Ongoing research suggests female workers are held to higher standards in job assessments. They are acknowledged less for creativity and technical expertise, their contributions are infrequently connected to business outcomes; guidance or praise supervisors do offer is vague{\field{\*\fldinst{HYPERLINK "scrivcmt://56520F0D-96C7-4028-A668-9B6D127FD46D"}}{\fldrslt 
\f1\fs24 \cf3 <$Scr_Cs::2>
\f2\fs28 [#Correll2016]
\f1\fs24 \cf0 <!$Scr_Cs::2>
\f0\fs28 .}}\
Students display a similar bias. 
\f1\fs24 \cf2 <$Scr_Cs::1>
\f2\fs28 [Data]({\field{\*\fldinst{HYPERLINK "http://benschmidt.org/profGender/"}}{\fldrslt \cf2 http://benschmidt.org/profGender/}})
\f1\fs24 \cf0 <!$Scr_Cs::1>
\f0\fs28  from 
\f1\fs24 \cf2 <$Scr_Cs::1>
\f2\fs28 [Rate My Professors]({\field{\*\fldinst{HYPERLINK "http://www.ratemyprofessors.com/"}}{\fldrslt \cf2 http://www.ratemyprofessors.com/}})
\f1\fs24 \cf0 <!$Scr_Cs::1>
\f0\fs28  suggest female lecturers should be "helpful", "clear", "organised" and "friendly". Men, instead, are praised (and criticised) for being "smart", "humble" or "cool"{\field{\*\fldinst{HYPERLINK "scrivcmt://C055CAE9-7E90-4D22-ABFC-5A96817E9476"}}{\fldrslt 
\f1\fs24 \cf3 <$Scr_Cs::2>
\f2\fs28 [#Schmidt2015]
\f1\fs24 \cf0 <!$Scr_Cs::2>
\f0\fs28 .}} A study of teaching evaluations similarly finds students value preparation, organisation and clarity in female instructors; their male counterparts are considered more knowledgable, praised for their "animation" and "leadership" and given more credit for contributing to students' intellectual development
\f1\fs24 \cf3 <$Scr_Cs::2>
\f2\fs28 [#Boring2017]
\f1\fs24 \cf0 <!$Scr_Cs::2>
\f0\fs28 .\
TO ADD:\
Readability scores may be capturing something not related to readability.\
Readability scores may be capturing the fact that referees are less interested in female work. This suggests a systematic bias against women in peer review, but is not necessarily the *fault* of individual referees. Instead, it just reflects another---albeit no less insiduous---bias taht results from systematic underrepresentation of women. However, the readability gap remains after controlling for detailed *JEL* codes. Thus, this must mean that referees are systematically less interested in women's work even after controlling for highly specific sub-fields. That is, male-authored papers are more appealing to editors and referees even compared to female-authored papers in the exact same field.\
The readability of text may be more important when interest is low than when it is high[#Klare1976,Fass1978]. It has also been shown that prior knowledge and beliefs about a topic improved reading comprehension for a particular text[#Woern1977,Spilich1979,Chiesi1979]. Easier readability of a text has more benefits for those of less knowledge and interest than those of more. Advanced knowledge of a subject can "drown out" the effects of an otherwise difficult text. This study also suggested that when reader interest is high, comprehension is not improved by writing the material below, rather than at, the grade level of the readers. When interest is low, however, comprehension is improved by writing the materials below, rather than at, the reading level of the readers.\

\f1\fs24 <$Scr_Ps::0>
\f0\fs28 A remaining concern is whether peer review actually affects manuscript readability. In a review of prestigious biomedical journals, [#Boutron2016;] find that 47 percent of editors clearly request that referees evaluate the language of a manuscript they are reviewing. Additionally, a review of the comments posted on {\field{\*\fldinst{HYPERLINK "http://ShitMyReviewer.com"}}{\fldrslt ShitMyReviewer.com}}, quarter deal with writing quality, document structure or word choice/tone (FIGURE XXXXX).\
Thus underlying all of the conclusions presented in this paper is the implicit assumption that if some perfect measure of readability existed that incorporated these factors, it would conclude the same thing. Thus assumption implies that the effects presented in this paper suffer from attenuation {\field{\*\fldinst{HYPERLINK "scrivcmt://2985CDC3-9413-4BE4-984F-88DF0411D1A3"}}{\fldrslt bias.}} given the relatively large textual samples used in the paper, the effects presented in fact suffer from attenuation bias.\
Because readability scores omit these factors using them to infer causality between gender and any outcome they attempt to proxy for implicitly assumes that gender impacts these other facets in the same way that gender impacts readability. Or, in other words, if we *did* have a more comprehensive measure of readability, it would show the same thing.\
And in any case, readability scores are perfect (or almost perfect) predictors of sentence and word length. Thus, the figures presented in this paper will always capture differences in the weighted averages of these two measures.\
I do not measure "quality" with readability. Quality is multidimensional and in any way highly subjective---I challenge anyone to find more than two people to agree on the components most important to quality. Nevertheless, if readability is an unbiased proxy for it, then these results suggest women's papers are in fact higher quality.\
*Discuss classicial measurement error vs. non-classical measurement error*.\
Classical measurement error is of most concern in small sample sizes with a high degree of variability between individuals because higher weights are placed on individual results. While I cannot rule out classical measurement error entirely as a factor driving my results, the fact that sample sizes are both relatively large and results do not appear to be driven by any individual results, suggests it is probably not, on its own, a particularly important factor.\
Thus, if non-classical measurement error prevents inferring gender differences in *readability* it is still the case that sentence-length and vocabulary complexity in female-authored papers is negatively affected by peer review. \
Thus, should non-classical measurement error prevent inferring readability between genders, one must nevertheless confront the observation that sentence-length and vocabulary complexity in female-authored papers is negatively affected by peer review. \
The weighted average of these two variables is informative in much the same way that the general "readability" inference may be.\

\f1\fs24 <!$Scr_Ps::0>}