<?xml version="1.0" encoding="UTF-8"?>
<SnapshotIndexes Version="1.0" BinderUUID="B4274C52-4B25-452A-92C4-11AB5031CDD2">
    <Snapshot Date="2016-05-30 14:12:33 +0100">
        <Title>Untitled Snapshot</Title>
        <Text>Ladies, there aren't very many of us on economics faculties. Only a third, fifth and tenth of assistant, associate and full professors, respectively, are women[#Romero2013]. Compared to other faculties---including engineering and the physical sciences---female economists are less likely to make tenure, take longer when they do and earn significantly less than their male peers[#Ginther2004,Ceci2014].
These statistics are uncomfortable but their causes myriad: women's career choices, motherhood, a tendency to discourage girls from pursuing math and, yes, bias. Lab experiments suggest women are subject to tougher standards[#Foschi1996], rated less qualified[#Reuben2014,Moss-Racusin2012] and given less credit than men[#Heilman2005]. In several surveys female academics report bias from their superiors, peers and students[see, *e.g.*,\]\[][#Williams2015].
Evidence of gender bias in academic publishing is harder to find. Although there is a tendency within the general population to rate articles assigned male names higher[#Goldberg1968,Paludi1983], the population of journal referees appears remarkably bias-free[#Borsuk2009,Lloyd1990]. Nearly every investigation of individual journals---from the *Journal of the American Medical Association* to the *American Economic Review*---reports weak or no evidence that gender impacts acceptance rates. Women, it appears, face bias everywhere *except* when submitting articles for peer-review.
Undoubtedly, academic journals are paradigms of objectivity. Reviewers are people of science. Whether or not that science comes from a man, a woman or a chimpanzee is theoretically irrelevant. Nevertheless, reviewers are also human and humans of both sexes form preconceived gender stereotypes which frustrate disinterested evaluation. If women are stereotypically  assumed less capable at math, logic and reasoning than men[#Reuben2014] and generally need more evidence to rate as equally competent[#Foschi2000] then by extension some well-intentioned reviewers might (unknowingly) scrutinise their papers more closely, demand a larger number of revisions and, in general, be less tolerant of complicated, dense writing.
I concentrate on the third hypothesis: do reviewers require clearer, more concise writing from women than they do men? For, if referees hold female- and male-authored papers to identical standards, the latter should be just as coherently written as the former.
I find that it is not. Using the Flesch Reading Ease, Flesch-Kincaid, Gunning Fog, Dale-Chall and SMOG scales, I analyse the readability of 9,123 article abstracts published in the *American Economic Review* (*AER*), *Econometrica* (*ECA*), *Journal of Political Economy* (*JPE*) and *Quarterly Journal of Economics* (*QJE*) from 1950--2015. Abstracts written by women are 2--6 percent more readable than those by men.
First, women write better than men after controlling for editor, journal, year and *JEL* classification. Thus, the gap did not form in response to specific policies or time periods nor is it caused by women writing on topics that are easier to understand. The gap is unchanged despite proxies of article quality and author competency and productivity---meaning factors correlated with gender but actually related to knowledge, intelligence or creativity are not driving the gap.
Second, I compare the readability of NBER working paper abstracts with the readability of their final, published versions. The gap indeed widens at precisely the moment papers undergo peer review. The difference is substantial---the gap is 1.5--3 times higher in published articles than it is in their working paper versions---and highly significant.
Third, women write better as they publish more papers but men do not, so the readability gap widens over authors' careers. In fact, there is no significant gender difference in abstract readability for authors' first publication. The gap is therefore unlikely fully explained by either the residual impact of stricter writing standards for women at an earlier stage in their eduction or inherent gender differences in writing clarity. After that, however, the gap noticeably widens, and continues to grow: by their third publication in the data, women's papers are up to 12 percent more readable than mens. Growth is almost entirely because individual women become better writers as they publish more papers. Men, on the other hand, make virtually no improvements to their writing over the course of their lifetimes.
Fourth, because writing simply and directly takes time, one observable repercussion should be prolonged peer review for female authors. This is indeed the case. Using data from *Econometrica*---and controlling for many factors, including whether the author was a mother to young children and/or gave birth during peer review---I estimate female-authored papers need six months longer to complete peer review. The figure is highly significant.
Are female economists disproportionately native or fluent English speakers? Do men ignore editorial changes suggested by referees? Are female referees the toughest critics, and if so, are they more likely to review female-authored papers?
These and several alternative hypotheses are discussed in detail; the most straightforward explanation, however, is that journal referees are less willing to overlook a wordy paragraph or convoluted sentence when its author is female---and women get the message. Unfortunately, by demanding clearer phrasing and less jargon, referees inadvertently subject women to an added time tax. 
Consider Esther Duflo. She co-authored 17 papers in the journals and time-periods covered by the data---more than any other woman. If she publishes her 18th paper with no male co-authors, it will be 30 percent more readable than, say, Steven Levitt's 18th publication: "Testing for Racial Differences in the Mental Ability of Young Children". Should Ms. Duflo publish a 44th paper, it will be 75 percent more readable than Daron Acemoglu's 44th (and latest) paper was predicted to be and 116 percent more readable than it actually was. In this context, academia's "Publishing Paradox"---the unquestionable fact that men publish more journal articles than women---may not be such a paradox, after all.
Should journals cop all the blame? I doubt it. But by process of elimination they probably deserve at least part of it. First, women write better than men after controlling for primary *JEL* classification code, suggesting the gap is not the result of women writing on topics that are easier to explain.
The gender readability gap may, however, stem from factors unrelated to journals but that I do not or cannot control for. For example, female economists may be disproportionately native or fluent English speakers or men may just ignore editorial changes suggested by referees. Alternatively, female referees are assigned papers from women more often than are male referees[#Gilbert1994], so the gap may actually reflect gender differences in reviewing.
The most straightforward explanation, however, is that referees themselves are less willing to overlook a wordy paragraph or convoluted sentence when its author is female---and women get the message. In fact, since the late 1990s, women have *really* gotten the message. Although both male- and female-authored abstracts have become more readable since then, women's did so by significantly more. I cannot definitively say why this occurred but Google is my best guess and regressions of text readability on the number of annual Google searches suggest I may be on to something: each time search engine traffic doubled, the readability gap grew by at least !!GoogleGrowth percent.
As for double-blind review, it solves nothing and may make things worse. I find no evidence that it closes the gender readability gap and some evidence that it actually allows men to write sloppier. It's hard to square this with the policy's promise of anonymity and fairness other than to admit that double-blind review probably isn't that double-blind---even pre-internet almost half of *AER* referees correctly identified the authors they were "blindly" reviewing [#Blank1991].

</Text>
        <Comments>Economics, like pure science and mathematics fields, may be particularly susceptible since the percentage of female tenure/tenure track positions is low (below 20 percent) and it views itself as highly meritocratic[#McElroy2015,Kanter1977,Castilla2010,Williams2015].
Virtually all studies of gender differences in scientific publishing rates find men more productive than women[for a list, see\]\[][#Ceci2014]. In the journals and time periods covered by my data, men published on average 2.4 articles; women only 1.7. The difference widens as economists publish more frequently---recall, 38 men have published 18 or more times in the data, but no woman.
Thirty-eight men have published 18 or more times in the journals and time periods covered by the data. Mr. Levitt's paper was singled out because it was co-authored with Roland Fryer (a man) and its Flesch Reading Ease score (40) is closest to the predicted score (40.86) amongst papers published within the last decade. Jean-Jacques Laffont's 18th paper "Optimal Bypass and Cream Skimming", co-authored with Jean Tirol (also a man) scored closer (40.18) but was published in 1990.
[#Gilbert1994;] found that female editors were more likely to immediately reject papers regardless of author gender, but content recommendations (accept as is, accept if suitably revised, and revise and reconsider) were independent of author or reviewer gender.
Determining whether authors are native English speakers would be time-consuming, yet feasible; however, it is not clear how or even if native speakers write clearer than those that are non-native but highly fluent---and most of the authors in the data would fall in one of these two categories. 
Again, assumes Ms. Duflo publishes only with female co-authors. Mr. Acemoglu's 44th paper (as of 1 July 2015) is "Robust Comparative Statics in Large Dynamic Economies", co-authored with Martin Kaae Jensen (a man). Its predicted Flesch Reading Ease score is 42.85; its actual score is 34.47.
The *JEL* classification system categorises literature in economics according to subject matter. The hierarchy's highest level are the 20 categories used in this analysis. Controlling for 440 tertiary *JEL* classifications has no effect and is reported in the Online Appendix.
*Behavioral Ecology* switched to double-blind review in 2001 and increased the number of papers with female first authors[#Budden2008a]. Whether that increase was due to bias or the universal upward trend in female authorship, however, is debatable[#Webb2008,Budden2008b,Whittaker2008,Budden2008c].</Comments>
    </Snapshot>
    <Snapshot Date="2016-06-01 11:25:09 +0100">
        <Title>Untitled Snapshot</Title>
        <Text>Ladies, we aren't that common in economics. Only a third, fifth and tenth of assistant, associate and full professors, respectively, are women[#Romero2013]. Compared to other faculties---including engineering and the physical sciences---female economists are less likely to make tenure, take longer when they do and earn significantly less than their male peers[#Ginther2004,Ceci2014,Sarsons2015].
These statistics are uncomfortable but their causes myriad: women's career choices, motherhood, a tendency to discourage girls from pursuing math and, yes, bias. Lab experiments suggest women are subject to tougher standards[#Foschi1996], rated less qualified[#Reuben2014,Moss-Racusin2012] and given less credit than men[#Heilman2005]. In several surveys female academics report bias from their superiors, peers and students[see, *e.g.*,\]\[][#Williams2015].
Evidence of gender bias in academic publishing is harder to find. Although there is a tendency within the general population to rate articles assigned male names higher[#Goldberg1968,Paludi1983,Smyk2016], the population of journal referees appears remarkably bias-free[#Borsuk2009,Lloyd1990]. Nearly every investigation of individual journals---from the *Journal of the American Medical Association* to the *American Economic Review*---reports weak or no evidence that gender impacts acceptance rates. Women, it appears, face bias everywhere *except* when submitting articles for peer-review.
Undoubtedly, academic journals are paradigms of objectivity. Reviewers are people of science. Whether or not that science comes from a man, a woman or a chimpanzee is theoretically irrelevant. Nevertheless, reviewers are also human and humans of both sexes form preconceived gender stereotypes which frustrate disinterested evaluation. If women are stereotypically assumed less capable at math, logic and reasoning than men and generally need more evidence to rate as equally competent then by extension some well-intentioned reviewers might (unknowingly) scrutinise their papers more closely, demand a larger number of revisions and, in general, be less tolerant of complicated, dense writing.
I concentrate on this third hypothesis. Do reviewers require clearer, more concise writing from women than they do men? For, if referees hold female- and male-authored papers to identical standards, the latter should be just as coherently written as the former.

In the English language, a more clearly written paper is the better paper, all things equal. Thus, papers held to a general higher standard should be generally better written
If female-authored papers *are* scrutinised more closely, they probably end up clearer and more concisely written than 
If female-authored papers *are* scrutinised more closely, 
Investigating this hypothesis directly requires access to confidential referee reports, which I do not have. Yet, if female-authored papers *are* scrutinised more closely, their papers probably reflect this. One way they might is in their readability. In the English language, a more clearly written paper is the better paper, all things equal.
How they reflect it is unclear. Women's papers may contain more robustness checks or cite more thoroughly the literature. Alternatively, 
 use clearer, more concise language.
I concentrate on this third hypothesis. In the English language, a more clearly written paper is the better paper, all things equal. Yet if female-authored papers are more heavily scrutinised and that scrutiny is unwarranted, 
Direct investigation requires referee reports, which are understandably private. Yet if unwarranted scrutiny is applied to female-authored papers, the quality of those papers should reflect this
those papers should reflect that---and actually *be* higher quality. While quality is often subjective, on one dimension, it is not: in the English language, a more clearly written paper is the better paper, all else equal. Clearer writing takes less effort to understand---it is more "readable". And while readability itself is subjective, factors highly correlated with it are not, including simple, familiar vocabulary and short sentences.
Hundreds of readability scores exist that exploit this relationship. I concentrate on the five more widely used, tested and reliable measures: The Flesch Reading Ease, Flesch-Kincaid, Gunning Fog, Dale-Chall and SMOG scales. With these scores, I analyse the readability of 9,123 article abstracts published in the *American Economic Review* (*AER*), *Econometrica* (*ECA*), *Journal of Political Economy* (*JPE*) and *Quarterly Journal of Economics* (*QJE*) between 1950--2015.
I concentrate on the third hypothesis: do reviewers require clearer, more concise writing from women than they do men? For, if referees hold female- and male-authored papers to identical standards, the latter should be just as coherently written as the former. My identification strategy is effectively a process of elimination. I first establish that the readability gap exists. I next establish a causal link between the timing of peer review and formation (or widening) of the gap. Finally, I document numerous stylised facts about the gap that a coherent theory would need to account for.
First, abstracts written by women are 2--6 percent more readable than those by men. Women write better despite controls for editor, journal, year and *JEL* classification; that remains unchanged when also proxying for article and author quality. This means the readability gap probably wasn't (i) a response to specific policies in earlier eras; (ii) caused by women writing on topics that are easier to explain; nor (iii) generated by factors correlated with gender but really related to knowledge, intelligence and creativity.
Second, the readability gap widens during peer review. When comparing National Bureau of Economic Research (NBER) working papers to their final, published versions, I find the latter's gap up to three times higher. Working paper readability is unsurprisingly highly correlated with a published article's readability, but explicitly controlling for it has little impact on gender differences---women's papers remain 2--4 percent better written. While both NBER working paper and their final published versions are exposed to other external influences that might impact readability, only the latter is exposed to the peer review process. By comparing readability in both papers, I can isolate additional effects of gender on readability relative to the consequences of such exposure before peer review. Assuming the precise timing of peer review is uncorrelated with other gender-specific factors that affect readability, this finding suggests a causal link between the process of peer review and the gap's formation.
Third, there is no significant gender difference in abstract readability for authors' first publication in the data. Since readability scores are more gender neutral for first time publications, it's unlikely fully explained by either the residual impact of stricter writing standards for women at an earlier stage in their eduction or inherent gender differences in writing clarity. For, if either were true, a significant persistent gender difference should be present regardless of previous publication counts---and especially in the one with the largest sub-sample.
Fourth, women's writing gradually gets better but men's does not, meaning the readability gap widens over authors' careers. Driving this growth are individual women making rhetorical improvements that men do not---by the third article, female prose is up to 12 percent clearer. Why would one gender continually invest in writing well but the other not? Additionally, although both first and subsequent publications are exposed to external influences that might impact readability, only the latter contain papers written *after* authors had been exposed to peer review. This suggests that female authors write well not merely in response to explicit criticism in referee reports, but also by internalising the experience and adapting for the next.
Fifth, female-authored papers need six months longer to complete peer review. This estimate is based on data from *Econometrica*, controls for relevant factors---including whether the author was a mother to young children and/or gave birth during peer review---and is highly significant. Prolonged peer review for female authors makes sense---writing well takes time---but is also a cost borne especially by women.
Several potential explanations are explored. Among them: Are female economists disproportionately native or fluent English speakers? Do men ignore editorial changes suggested by referees? Are female referees the toughest critics, and if so, are they more likely to review female-authored papers?
The most straightforward explanation, however, is that journal referees are less willing to overlook a wordy paragraph or convoluted sentence when its author is female---and women get the message. Unfortunately, by demanding clearer phrasing and less jargon, referees inadvertently subject women to an added time tax.
The contribution of this paper is threefold. Its primary contribution is to shed light on the peer review *process*. To the best of my knowledge, my study is the first not only to suggest bias could exist in the process despite its absence in the outcome, but also to document such evidence. 
to the best of my knowledge, it is the first study to document evidence of gender bias in the peer review process. 
As mentioned earlier, gender has no apparent impact on journal acceptance rates. But a gender neutral outcome does not preclude a gender neutral *process*---and to the best of my knowledge, my paper is the first to suggest it. Determining whether female economists are unfairly scrutinised in referee reports suffers from several identification issues, chief among them the fact that accessing those reports is impossible thanks to the privacy ensconced in peer review. To circumvent this limitation, my paper notes that *if* women are subject to greater scrutiny, and that added scrutiny 
</Text>
        <Comments>In the English language, a more clearly written paper is the better paper, all things equal.
Economics, like pure science and mathematics fields, may be particularly susceptible since the percentage of female tenure/tenure track positions is low (below 20 percent) and it views itself as highly meritocratic[#McElroy2015,Kanter1977,Castilla2010,Williams2015].
*Behavioral Ecology* switched to double-blind review in 2001 and increased the number of papers with female first authors[#Budden2008a]. Whether that increase was due to bias or the universal upward trend in female authorship, however, is debatable[#Webb2008,Budden2008b,Whittaker2008,Budden2008c].</Comments>
    </Snapshot>
    <Snapshot Date="2017-04-16 10:58:36 +0100">
        <Title>Untitled Snapshot</Title>
        <Text>

Ladies, we aren't that common in economics. Only a third, fifth and tenth of assistant, associate and full professors, respectively, are women[#Romero2013]. Female economists are less likely to make tenure, take longer when they do and earn much less than their male peers[#Bandiera2016,Ceci2014,Ginther2004,Sarsons2015,Weisshaar2014].
These statistics are uncomfortable, but their causes are myriad: lower publishing rates, career choices, motherhood and, probably, bias. In lab experiments women are subject to tougher standards. Their qualifications and ability are underestimated[#Foschi1996,Grunspan2016,Moss-Racusin2012,Reuben2014]. Female-authored manuscripts are evaluated more critically[#Goldberg1968,Krawczyk2016,Paludi1983]; when collaborating with men, women are given less credit[#Heilman2005,Sarsons2015].
Peer review is not immune. Using five reliable measures of writing clarity, I show that female-authored articles published in top economics journals are better written than equivalent papers by men.
Additionally, this readability gap widens precisely while papers undergo peer review.
Because better writing takes effort to compose, it likely prolongs female review time---indeed, I find female female-authored papers spend six months longer in peer review---and probably contributes to lower publishing rates.
I explore many interpretations---*e.g.*, Are women more sensitive to criticism? Is better writing due to risk aversion? Do women's papers deserve more scrutiny because they aren't as good? The only straightforward explanation consistent with the data, however, is that referees apply higher standards to women’s writing. Because better writing takes effort to compose, higher standards prolong female review time---by six months at *Econometrica*---and likely contribute to lower publishing rates. Tougher standards applied more broadly reduce women’s output; ignoring them undervalues female labour and may confound estimates of gender discrimination.
Prior research indicates journal acceptance rates are genuinely bias-free [see, *e.g.*,\]\[][#Abrevaya2012,Blank1991,Borsuk2009,Gilbert1994,Lloyd1990]. To the best of my knowledge, however, gender neutrality is established in only a narrow context (publication outcomes) using this single indicator. I ask a different question. Men's and women's papers may be published at comparable *rates*, but are they reviewed with comparable *scrutiny*? For, if women are stereotypically assumed less capable at math, logic and reasoning than men and generally need more evidence to rate as equally competent, some well-intentioned referees might (unknowingly) inspect their papers more closely, demand a larger number of revisions and, in general, be less tolerant of complicated, dense writing.
Complicated, dense writing is my focus. In the English language, more clearly written prose is better prose, all things equal. Thoughtful word choice and simple sentence structure make text easier to understand, more interesting to read and expose inconsistencies long-winded writing often hides. Journal editors tend to agree---*Econometrica* asks authors to write "crisply but clearly" and to take "the extra effort involved in revising and reworking the manuscript until it will be clear to most if not all of our readers" ([*Econometrica* submission guidelines](http://www.econometricsociety.org/publications/econometrica/information-authors/instructions-submitting-articles), June 2016).
If referees hold female- and male-authored papers to identical standards, both should be equally well written. To test this, I rely on a relationship familiar to linguists and educators: simple vocabulary and short sentences are easier to understand and straightforward to quantify. Using the five most widely used, studied and reliable formulas to exploit this, I analyse 9,123 article abstracts published in the *American Economic Review* (*AER*), *Econometrica* (*ECA*), *Journal of Political Economy* (*JPE*) and *Quarterly Journal of Economics* (*QJE*).
I find female-authored abstracts are 1--6 percent more readable than those by men. Women write better despite controls for editor, journal, year and primary and tertiary *JEL* classification; that remains unchanged when proxying for article and author quality. This means the readability gap probably wasn't (i) a response to specific policies in earlier eras; (ii) caused by women writing on topics that are easier to explain; nor (iii) generated by factors correlated with gender but really related to knowledge, intelligence and creativity.
Additionally, the gender readability gap widens during peer review. I compare National Bureau of Economic Research (NBER) working papers to their final, published versions; the gap is three times larger for the latter. While both papers are exposed to many factors that impact readability, only published articles are subject to peer review. By comparing the two, influences unrelated to immediate peer review are isolated from those that are; assuming the former are not correlated with the latter's timing, a widening gap suggests a causal link.
PARAGRAPH ON SPENDING 6 MONTHS LONGER IN PEER REVIEW
Two possible explanations can account for this gap: either referees subject female-authored papers to added scrutiny, or women choose themselves to exert more effort. Both possibilities imply women spend more time than men on a given task. On the positive side, it increases quality; on the other hand, it reduces quantity. Either could explain academia's "Publishing Paradox". Unequal time spent making revisions leads to unequal time conducting new research; as a result, women write fewer papers.
Nevertheless, I find the more plausible explanation is indeed because referees subject female-authored papers to greater scrutiny. First, women's writing gradually gets better but men's does not---meaning gender differences in (i) biology/behaviour and/or (ii) knowledge about the advantages of writing well cannot resolve the gap. According to both interpretations, readability essentially diverges because women voluntarily accept the costs of good writing (longer drafting and revision stages) despite receiving no tangible benefit (acceptance rates do not change). Initially, this explanation is perfectly plausible; indefinitely, it is not: wouldn't individual women eventually figure out there's nothing to gain by writing well---and then do it less? If so, gender differences in readability should decline as authors gain experience in peer review.
Instead, they increase. Between authors' first and third published articles, the gap grows by 12 percent. Evidence does not suggest senior female economists co-author with more women. Nor are initially bad female writers leaving academia. Instead, women---and only women---seem to figure out that writing well makes peer review smoother; they write subsequent papers clearer from the start.
Points one to three provide strong evidence that peer review is at least partially responsible for better writing in female-authored papers. But is it given that female-authored papers invite undue scrutiny? In [][p3alternatives], I explore several alternative hypotheses---many of which have nothing to do with bias and some that exonerate peer review, too. Among them: Are female economists disproportionately native English speakers? Are female referees the toughest critics, and, if so, are they more likely to review female-authored papers? Do manuscripts written by women deserve more criticism because they aren’t as good?
As [][p3Alternatives] also illustrates, however, the only straightforward explanation consistent with the data is that referees are disproportionately critical of female-authored papers. Clearer sentences, less jargon and more scrutiny aren’t bad things. Added attention reduces discriminatory outcomes[#Bartos2016]. It doubtless leads to a better final product: papers that are easier to understand enjoy wider, more diverse readership; closer review catches logical mistakes and leads to fewer factual errors.
Still, adding robustness checks, clarifying proofs and making sentences even marginally more readable takes time. [][p3AppendixModel] illustrates this idea using [#Bartos2016;]’s formative model linking discrimination and attention. The major change is a simple extension that assumes referees pass on to authors some of the cost of evaluating their papers. This prolongs peer review directly---referees spend more time evaluating women’s papers and women spend more time responding---and indirectly---female authors take longer drafting future papers. 
I estimate the direct effect results in female-authored papers spending ***six months longer*** in peer review. This estimate is based on submit-accept times at *Econometrica*, is consistent across a range of specifications and, in addition to other factors, controls for motherhood and giving birth. It appears to dominate in papers written by early career academics. In fact, there is very little gender difference in readability in the draft version of an authors' first publication---although a large difference does emerge by the time those same articles are actually published. The indirect effect---i.e., women spending more time upfront drafting their papers---increasingly dominates as women gain experience in peer review.
In [][xxxx], I look at the indirect effect. I find the direct effect dominates among early career academics; the indirect effect dominates later in their careers. There is very little gender difference in readability in the draft version of authors' first publication---although a significant difference does emerge by the time those articles are eventually published. Initial drafts of women's second publications, however, are already much better written than men's---evidence of an indirect effect---although the still further widens during peer review.
Spending six more months in peer review may explain academia's "Publishing Paradox". Unequal time spent making revisions leads to unequal time conducting new research; as a result, women write fewer papers. 
undoubtedly hurting women’s productivity and probably, as a consequence, promotion rates, too.
 explain academia “Publishing Paradox”: 
Higher standards impose quantity vs. quality tradeoffs that may may explain lagging female wages and productivity, more generally. Work that is evaluated more critically *at any point in the production process* will be systematically better (holding prices fixed) or systematically cheaper (holding quality fixed). This reduces women's wages---for example, if judges require better writing in female-authored briefs, female attorneys must charge lower fees and/or under-report hours to compete with men---and distorts measurements of female productivity---billable hours and client revenue decline; female lawyers appear less productive than they truly are.
Higher standards impose quantity vs. quality tradeoffs that characterise many instances of female output. According to raw numerical counts, women produce less than men. Female academics publish fewer academic journals[#Ceci2014]; female physicians see fewer patients[#Bloor2008] and submit fewer grant proposals[#Gordon2009,Klos2013]; female reporters write fewer front-page bylines[#Crozier1999]; female novelists produce less nonfiction output[#Waisbren2008]; female real estate agents list fewer homes[#Trulia2011].
When ranked by narrowly defined outcome measures, however, women generally outperform men. Female students earn better grades[#Voyer2014]; female auditors are more accurate and efficient[#Chung2001,ODonnell2001,Ittonen2013,Niskanen2011]; congresswomen secure more federal funding for their districts, sponsor more legislation and score higher on a composite measure of legislative effectiveness[#Anzia2011,Volden2013]; houses listed by female real estate agents sell for higher prices[#Seagraves2013,Salter2012]; patients treated by female physicians are less likely to die or be readmitted to hospital[#Tsugawa2016]; female pilots are involved in fewer fatal accidents[#Vail1986,Bazargan2011]. Moreover, evidence on work habits suggests women espouse traits---conscientiousness, tenacity and diligence---that are likely correlated with quality: female physicians consult longer with patients[#Roter2004]; female politicians fundraise more aggressively[#Jenkins2007]; female faculty commit fewer instances of academic misconduct[#Fang2013]; female lawyers make fewer ethical violations[#Hatamyar2004]; female pharmacists are less likely to face performance-related disciplinary action[#Schafheutle2011].
Many of these differences are undoubtedly influenced by innate gender differences in biology and behaviour. Irrespective of their origin, however, most have intrinsic value that, under normal circumstances should be appropriately rewarded in an unbiased marketplace. Property listed by female real estate agents sell for higher prices; in the absence of higher standards, women would charge more to sell a house. They do not[#Trulia2011]. Patients treated by female physicians are less likely to die or be readmitted to hospital, in the absence of higher standards, visiting a female doctor would cost more. It does not[#XXXXXX]. Congresswomen are better legislators; in the absence of higher standards, they would be elected at higher rates. They are not[#XXXX]. Female-authored manuscripts are better written; in the absence of higher standards, women's papers would be published in academic journals at higher rates. They are not[#Ceci2014].
The impact on productivity may be even more subtle. I find senior women submit better written papers *ex ante* to offset biased evaluation *ex post*. Assuming women routinely internalise higher standards in related roundabout ways, they could contribute to more general labour market phenomena---*e.g.*, sectoral and occupational gender concentration[see, *e.g.*,\]\[][#Blau2016,Cortes2016,Pertold-Gebicka2016] and women's tendency to apply only to jobs for which they are fully qualified[for a discussion, see, *e.g.*,\]\[][#Mohr2014]. In academia, fewer papers justifies lower promotion rates, which in turn may contribute to a "Leaky Pipeline" as women seek fairer employment opportunities, elsewhere.
This paper primarily contributes to research on the impact of biased evaluation on productivity measurement[for theories specific to academia, see, *e.g.*,\]\[][#Lee2016,Bright2016]. Higher standards raise quality at the expense of quantity. Performance indicators that weight the latter's fall more heavily than the former's rise appear artificially low. In economics, the argument was most recently made in a study of racial preferences in Major League Baseball[#Parsons2011]. The authors find that race affects umpire calls, umpire calls influence players' behaviour and players' behaviour impacts performance metrics. As a result, common baseball statistics underestimate the talent of disadvantaged (usually minority) pitchers and overestimate the talent of advantaged (usually white) pitchers. An important contribution of my paper is to confirm this general point both in the context of gender discrimination and within a highly educated, professional working environment.
This suggests using using caution when employing shallow performance indicators to explain gender wage gaps. Interpretations that don't assume men and women produce work of comparable quality. If used to explain gender wage gaps, they will undervalue women's work and may confound estimates of labour market discrimination.
This paper also suggests a novel technical instrument that may be used to overcome bias inherent in measures of subjective evaluation. In the presence of higher standards, subjective quality measures are themselves biased. I use readability formulas to overcome this problem. Readability formulas are transparent, objective and accurate measures of one component on which papers are evaluated during peer review--writing clarity. Similar tests to expose higher quality work may uncover higher standards in a variety of situations: successful business proposals, published "letters to the editor" or annual report introductions. Readability scores could also be employed to produce more accurate measures of labour market wage gaps---by instrumenting for unobserved bias in the subjective productivity measures themselves. Readability scores have their limitations [see][p3MeasuringReadability] and their use in this manner applies to just a narrow set of questions. Nevertheless, they appear to be a largely ignored, naturally occurring source of pseudo-experiments relevant to research on gender or racial bias---and differential group treatment, more generally.
Finally, I hope this paper contributes to research seeking precise explanations for the persistent gender wage gap. Evidence suggests women do not bargain for higher salaries and may be less willing to work in competitive environments. Women may be penalised for taking on too much responsibility at home, and jobs may be structured to reward long, flexible hours---a situation that tends to favour men[#Goldin2016]. To these explanations I add the idea that women are still subjected to a form of discrimination that manifests itself as higher standards. Gender wage gaps then emerge when the positive side of higher standards---better quality output---are not commensurately rewarded. To the extent that higher standards require time investments and induce similar behavioural adjustments that reduce the quantity of female output, they may even produce superficial productivity measures that mask their effect.
The remainder of this paper is organised as follows. [][p3Data] describes the data and readability measures used in the analysis. [][p3Results] presents results; a detailed discussion (including possible explanations) comes next ([][p3Discussion]). [][Conclusion] concludes.</Text>
        <Comments>Predictably, giving birth slows down poor review. The coefficient on motherhood, however, is consistently negative (indicating a productivity boost) and almost always highly significant when subjected to several robustness checks. This result is provocative and discussed in [][p3Duration]. I encourage interpreting it with caution, however, given (i) counterintuitive results; (ii) the analysis did not intend to measure motherhood’s impact on review times; and especially (iii) only a small number of mothers with young children are published in *Econometrica*.
A possible exception is *Behavioral Ecology*, which increased its number of female first-authored papers after switching to double-blind review in 2001[#Budden2008a]. Whether that increase was due to bias or the universal upward trend in female authorship, however, has been somewhat controversial[#Budden2008b,Budden2008c,Webb2008,Whittaker2008].
Readability scores are highly correlated across an article's abstract, introduction and discussion sections[#Hartley2003a]. See [][p3Data] for further discussion.
The *American Economic Review* rejected Robert Lucas's paper "Expectations and the Neutrality of Money" for insufficient readability; one referee wrote "If it has a clear result, it is hidden by the exposition"[\]\[p. 172][#Gans1994]. In a random selection of 100 posts on [Shit My Reviewers Say](http://shitmyreviewerssay.tumblr.com/submit), a quarter deal with writing quality, document structure or word choice/tone.
At a bare minimum, women would not be expected to write *more* clearly with greater exposure to peer review.
While 1--6 percent seems small, it is based on a single paragraph. Assuming a similar standard applies to every paragraph in a paper and improving each one takes slightly more time, the accumulated impact may be substantial.
For a discussion on the reliability of readability formulas, see [#DuBay2004;] and [][p3MeasuringReadability]. A sixth commonly used measure is the Lexile Framework. Because its formula and software are proprietary, I do not include it in the analysis.
The underlying assumption driving the result is that women’s papers are more costly to evaluate. As discussed in [][p3AppendixModel], higher evaluation costs can be motivated by any of the three prominent theories of discrimination---*i.e.*, taste-based[#Becker1971], statistical[#Phelps1972,Arrow1973] or screening[#Cornell1996].
The evidence on general accident rates (including non-fatal accidents) is mixed. [#McFadden1996;] found no difference in female vs. male accident rates after adjusting for pilot experience and age. [#Walton2016;] found female accident rates were *higher* among inexperienced pilots but *lower* among experienced pilots.
Evidence in several countries suggests female pharmacists are less likely to commit criminal offenses (prescription fraud, drug trafficking, etc.) and minor professional misdemeanours (inadequate written records, stock, etc.)[#Tullett2003,Payne1997]. Although self-reported survey evidence does not suggest female pharmacists make fewer dispensing errors[#Szeinbach2007], evidence from a laboratory experiment indicates the opposite[#Family2013]. Similar gender trends have been found for physicians, dentists and other medical professionals[for a review of studies and discussion, see\]\[][#Firth-Cozens2008].
Any female behaviour that also improves acceptance rates would result in female-authored papers being disproportionately represented in academic journals. They are not[#Ceci2014]. See [][p3alternatives] for further discussion on this point in the context of risk aversion.
This study investigates the revision process conditional on passing initial screening, at which point most manuscripts are ultimately accepted[#Duflo2016]. These conditions resemble [#Bartos2016;]'s "lemon-dropping" market---*i.e.*, average candidates are acceptable. In contrast, initial screening by scholarly journals more likely resembles "cherry-picking" markets, in that most manuscripts are not selected. Attention and labour market discrimination are inversely related in lemon-dropping markets, only.
[#Bloor2008;]'s analysis considers only full-time (or maximum part-time), salaried physicians in the U.K. Similar results are found in Canada and the U.S., where physicians are paid on a per-service basis[#CICH2005,Benedetti2004].
[#Seagraves2013;] find that normal houses (*i.e.* homes not sold under special sales conditions, such as foreclosures, fixer-uppers, corporate-owned properties, transfers and estate sales) sell at a significantly higher price when listed by a female real estate agent. While the authors do find buyers pay less if they are represented by a male agent, the effect is only present for homes sold under special sales conditions. In an earlier study, [#Turnbull2007;] did not find any significant gender difference in selling performance for listing and selling agents.
Many thanks to Kevin Schnepel for suggesting this idea.
They target a wider variety of potential donors using a wider variety of methods (direct mail, television advertisements, *etc.*)[#Jenkins2007].</Comments>
    </Snapshot>
</SnapshotIndexes>