<?xml version="1.0" encoding="UTF-8"?>
<SnapshotIndexes Version="1.0" BinderUUID="63CB6D77-211B-489C-AE1C-02E856B6D37A">
    <Snapshot Date="2016-04-10 15:52:52 +0100">
        <Title>Untitled Snapshot</Title>
        <Text>A gender gap exists between the readability of male- and female-authored abstracts in top economics journals. It emerges only after authors' first publication, grows as they publish more papers and even widens when controlling for primary *JEL* classification. While several explanations are imaginable, one possibility is that referees demand more detailed revisions when reviewing papers by women---which in this section I show may well be the case.
To investigate this hypothesis, I compare the impact of gender on readability in two different versions of the same article: a "draft" released before the peer review process began and the published paper, which fully reflects changes made during peer review. A more pronounced gender gap in the latter probably means journal referees are tougher on women---or at least demand more from their prose---than they are on men.
A cursory glimpse of authors' institutional affiliations and papers' acknowledgements sections suggests a substantial portion of the articles in my dataset were originally released as National Bureau of Economic Research (NBER) working papers. NBER working papers "have not undergone the review accorded official NBER publications" and are "intended to make results of NBER research available to other economists in preliminary form to encourage discussion and suggestions for revision before publication" ([www.nber.com/papers](http://www.nber.org/papers.html)), making them an excellent source of "drafts"---papers that have not yet (or at least, not yet fully) undergone official peer review.
I matched one-fifth of the articles in my dataset to an NBER working paper. Two facts confirm that (a) NBER working papers are indeed versions of articles pre-peer-review; and (b) abstracts are considerably altered during the revision process. First, NBER abstracts are significantly longer than the abstracts of published articles---they contain more sentences, characters, words, syllables, polysyllabic words, difficult words and words per sentence ([](#p3tableSUP4)). Second, working papers were released on average 2.1 years prior to publication---*i.e.*, at approximately the same time they were submitted to peer review.
[](#p3tableSUP2)displays coefficients on the ratio of female co-authors from [](#eq:p3eq1) applied to the abstract readability of (1) published articles and (2) their working paper versions. (1) and (2) were estimated using feasible, generalised least squares to allow for error correlation across models. Dummies for years, journals and their interactions are included; because all papers in both samples share the same highest-ranked institution---NBER---institution fixed-effects are not.
Both female-authored published articles and working papers are better written; yet (and with the exception of the Dale-Chall score) the coefficient on the latter is estimated with far less precision---suggesting  a much more heterogeneous sample. Moreover, the gender readability gap is 1.5 to 9 times higher for the sample of published articles (third column). The difference is at least weakly significant for all five scores, providing reasonable evidence that journal referees do indeed apply tougher standards to women than they do men.
[](#p3tableSUP3) re-estimates [](#eq:p3eq1) using the readability of a published article's NBER working paper to explicitly isolate differences pre-existing peer review from those incurred during it. Rows one and two display the estimated coefficients of interest. Unsurprisingly, the readability of a working paper is positively and highly significantly correlated with readability in its published version---a one point increase in the former corresponds to an 0.8 point increase in latter. Nevertheless, the ratio of female co-authors remains a stubbornly persistent explanatory factor and roughly in line with estimates in columns (2) to (5) from [](#p3table4b)---again plausibly suggesting the review process itself contributes to gender differences in readability.
As discussed in [the introduction][p3Introduction], writing simply and directly takes time meaning that *if* the readability gap widens (or forms) during peer review, *then* female-authored papers should take longer to make it through the revision process. Most journals maintain careful records[see, *e.g.*,\]\[][#Ellison2002] but only *Econometrica* makes any kind of disaggregated data on the revision process publicly available---printed at the end of every paper is the date it was first submitted and the date final revisions were received. I extracted this information from digitised articles using the open source command-line utility `pdftotext` and then estimated [](#eq:p3eqSUP1) based on a similar exercise in [#Ellison2002;].where $\text{revision duration}_j$ is the time, in months, between the date manuscript $j$ was first submitted to *Econometrica* and the date the editorial office received the version that was ultimately published, $\text{max no. prior papers}_j$ is the number of prior papers published in any of the top four economics journals by article $j$'s most prolific co-author, $\text{no. pages}_j$ refers to the page length of the published article, $\text{no. authors}_j$ is article $j$'s co-author count and $\text{order in issue}_j$ is the order in which article $j$ appeared in an issue.
[](#p3tableSUP1)displays the coefficients from estimating [](#eq:p3eqSUP1). Longer papers take more time to review, as do papers with more co-authors[for a discussion, see \]\[][#Ellison2002] and those that appeared earlier in an issue; authors with an established publication history enjoy marginally faster reviews. All coefficients are highly significant.
Now for the coefficient of interest. Every paper published in *Econometrica* undergoes extensive revision---but women bear the brunt of it. In 2015, the average male-authored paper took 19.4 months to complete the entire review process; those by females took almost five months longer. In fact, the paper to undergo the lengthiest revisions---Ms. Andrea Wilson's "Bounded Memory and Biases in Information Processing"---alludes to a particularly arduous editing process.
&gt;This is a radical revision of my job market paper that I presented on the 2003 Review of Economic Studies Tour. I am indebted to Wolfgang Pesendorfer for extremely valuable guidance and advice throughout this project. I also thank Faruk Gul for his help in developing some ideas in the paper, and Ariel Rubinstein, the initial and final co-editors, five anonymous referees of this journal, and many seminar participants for useful comments. Throughout this editing, I have profited from the continued support of senior colleagues as well as my wonderful dog, Mavi.
This result actually mirrors a finding by [#Ellison2002;]. He finds male-authored papers published in the 1990s are accepted 57 days faster than are female-authored papers. The effect is weakly significant.
It's worth asking whether longer revision times are actually correlated with higher readability scores---and whether that differs by gender. To tease this out, I again duplicated each article $m_j$ times per [](#eq:p3eq3) and ran the fixed effects regression in [](#eq:p3eqSUP2)[](#p3tableSUP2) displays marginal effects for revision duration. Male effects estimated for male authors co-authoring with no females ($\beta_{2m}$); female effects for female authors co-authoring with no males ($\beta_{2f}+\beta_{3m}$).
According to the Gunning Fog, SMOG and Dale-Chall scores, lengthier revisions have no impact on the readability of male-authored texts; the Flesch Reading Ease and Flesch-Kincaid scores suggest they may, in fact, be inversely related, although the evidence is weak. For women, on the other hand, all five scores suggest a longer revision process leads to better written text, although only three are significant. In any case, the difference is at least weakly significant for all five scores.</Text>
        <Comments>[#Ellison;] evaluates whether author compositional effects have contributed to higher mean-accept times at *AER*, *Econometrica*, *JPE* and *QJE* as well as the *Review of Economic Studies*. I control for all significant factors he identified (Table 6, p. 963) with the exception of article citation counts and field dummies. To compensate, I have included a much more robust set of year and institution dummies. Indeed, if I saturate the model with the full set of year, institution and year-institution interaction dummies (4,512 effects in total), the coefficient on the ratio of female co-authors hardly changes and remains significant at 10 percent.
\input{$P3/equations/eqnSUP1.tex}
*Econometrica* began consistently printing this information at the end of every paper that was not originally presented as an Econometric Society lecture starting in March, 1970. Before 1970, only "A Capital Intensive Approach to the Small Sample Properties of Various Simultaneous Equation Estimators" (January, 1965) included the dates. "Separable Preferences, Strategyproofness, and Decomposability" (May, 1999) only printed the year it was submitted; I assumed the month was January.
\input{$P3/equations/eqnSUP2.tex}
Some NBER working papers were eventually published as multiple articles; others were combined into a single paper. Matches were first attempted using citation data from RePEc and then by searching NBER's database directly for papers not otherwise found but authored by an NBER family member.
\input{/Users/erinhengel/Desktop/p3tableSUP3.tex}
The average submission to publication time in *AER* was 2.3 years[#Goldberg2015]. [#Ellison2002;] found mean submit-accept times at *AER*, *Econometrica*, *JPE* and *QJE* were 1.75, 2.2, 1.7 and 1 year, respectively[#Ellison2002].
[#Ellison2002;] actually finds female-authored papers experienced shorter submit-accept times than male-authored papers in the 1970s and 1980s, a sample which also included the *Review of Economics and Statistics*. I did not find this to be the case in my own sample when including similar controls---the coefficient remained positive albeit much smaller and insignificant (possibly due to the small number of female co-authors: only 14 papers published before 1990 were solo female-authored and only 48 had at least one female author).
\input{/Users/erinhengel/Desktop/p3tableSUP4.tex}
\input{/Users/erinhengel/Desktop/p3tableSUP1.tex}
Standard errors are clustered by author; clustering by article results in slightly more significant figures (see the Online Appendix, Table X).
Male effect estimated with zero female co-authors and 2015 averages for the other three coefficients.
\input{$P3/tables/tex/tableSUP2.tex}
\input{/Users/erinhengel/Desktop/p3tableSUP2.tex}
Ms. Wilson submitted her paper in May, 2004; her final revisions were received one decade later (June, 2014). Although anecdotal, Ms. Wilson's experience is especially interesting given *Econometrica* only published 50 solo female-authored papers between 1950 and 2015 (1.9 percent of the total).</Comments>
    </Snapshot>
</SnapshotIndexes>